{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "QUESTION": "DETAILS",
    "TYPE": "ANSWER",
    "cellcol": "answercell"
   },
   "source": [
    "### Edit this cell to enter your name and PI. Then run the JavaScript cell below to identify answer and feedback cells.\n",
    "**Name: Aaron Bruce Smith**\\\n",
    "**PI: abs247** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "TYPE": "SPECIAL",
    "jupyter.outputs_hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var head=document.getElementsByTagName('head')[0],style = document.createElement('style'),css = '.answercell{background-color: #ffffcc;}.feedbackcell{background-color: #c8ecff;}.guidancecell{background-color: #f2c0d4;}';head.appendChild(style);style.type = 'text/css';style.appendChild(document.createTextNode(css));Jupyter.notebook.get_cells().map(function(cell) {if (cell.metadata['cellcol']!= undefined) {cell.element.addClass(cell.metadata['cellcol']);}});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var head=document.getElementsByTagName('head')[0],style = document.createElement('style'),css = '.answercell{background-color: #ffffcc;}.feedbackcell{background-color: #c8ecff;}.guidancecell{background-color: #f2c0d4;}';head.appendChild(style);style.type = 'text/css';style.appendChild(document.createTextNode(css));Jupyter.notebook.get_cells().map(function(cell) {if (cell.metadata['cellcol']!= undefined) {cell.element.addClass(cell.metadata['cellcol']);}});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "# TMA 03\n",
    "M269 requires all assignments to be submitted electronically, by following the\n",
    "link(s) from your StudentHome page to the online TMA/EMA service.\n",
    "\n",
    "If you foresee any difficulty with submitting your assignment on time then you\n",
    "should contact your tutor well in advance of the cut-off date.\n",
    "\n",
    "For further information about policy, procedure and general submission of\n",
    "assignments please refer to the\n",
    "[Assessment Handbook](https://help.open.ac.uk/documents/policies/assessment-handbook),\n",
    "which can also be accessed via your StudentHome page.\n",
    "\n",
    "The learning outcomes assessed by each questions are outlined at the head of\n",
    "the question.\n",
    "\n",
    "If you use an algorithm, data structure or operation that is not allowed in a\n",
    "part of a question, your answer to that part will be awarded zero marks.\n",
    "\n",
    "Your TMA should be opened and edited in Jupyter notebooks. Ensure you put your\n",
    "name and PI at the top of this document. You should run the second cell to\n",
    "highlight the answer cells in yellow.\n",
    "\n",
    "All of TMA 02 is in this document. There are five questions worth 100 marks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "## PART 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1 (34 marks)\n",
    "\n",
    "You should be able to answer this question after you have studied Chapter 8.\n",
    "\n",
    "This question tests the following learning outcomes:\n",
    "\n",
    "- Develop and apply algorithms and data structures to solve computational problems.\n",
    "- Explain how an algorithm or data structure works, in order to communicate with relevant stakeholders.\n",
    "- Analyse the complexity of algorithms to support software design choices.\n",
    "- Write readable, tested, documented and efficient Python code.\n",
    "\n",
    "This question is about the set and bag ADTs, and the corresponding Python classes `set` and `Counter`, introduced in Sections 8.4, 8.5 and 8.6.  The operations for the set ADT and the bag ADT are listed in Chapter 8 along with details of their Python implementations.\n",
    "\n",
    "In answering this TMA, remember that you can only use the Python data types, methods and functions listed in the chapter summaries, unless specified otherwise in this TMA.\n",
    "\n",
    "**The files `m269_tma03_filehandling.py` and `m269_util.py` should be in the folder with this TMA notebook.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q1(a) (3 marks)\n",
    "\n",
    "We wish to explore the differences between sets and bags, and in particular the effect of operators on these ADTs.\n",
    "\n",
    "In Python the main operators that can be used on sets and bags are as follows (Y and N indicate whether a given operator is available for that ADT).\n",
    "\n",
    "| Operator | Python | sets | bags |\n",
    "| :--- | :-- |:-- |:-- |\n",
    "| Intersection | `&` | Y  |  Y |\n",
    "| Union        | `\\|` |Y  |  Y |\n",
    "| Difference   | `-`  |Y  |  Y |\n",
    "| Sum   | `+`  | N  |  Y |\n",
    "\n",
    "Where an operator can be used for both sets and bags the effect may be slightly different in some cases.  The Sum operator for bags in Python, implemented using the `Counter` class, adds the counts of corresponding elements in the two bags. See [here](https://docs.python.org/3/library/collections.html#collections.Counter) for details and examples.\n",
    "\n",
    "The following code defines a simple test function and several sets whose members are individual characters, derived from character strings.\n",
    "\n",
    "Run this code to set up the test function and initialise the sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "TYPE": "CODEBLOCK",
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 and 1 makes 2 OK\n",
      "1 and 1 makes 2 OK\n",
      "2 and 2 makes 4 FAILED\n",
      "2 and 2 makes 4 FAILED\n",
      " got 4 \n",
      " instead of 5\n"
     ]
    }
   ],
   "source": [
    "def one_test(name, actual, expected, details:bool=False) -> None:\n",
    "    \"\"\"Report if test passed or failed.\n",
    "       Final argument is optional- if True, then details of failed test are displayed\n",
    "    \"\"\"\n",
    "    if actual == expected:\n",
    "        print(name, 'OK')\n",
    "    else:\n",
    "        print(name, 'FAILED')\n",
    "        if (details):\n",
    "            print(' got', actual, '\\n instead of', expected)\n",
    "\n",
    "# Examples of using the one_test function, with and without details.\n",
    "# If the \"details\" argument is True then a FAILED test gives information\n",
    "# about the expected and actual results of the test.\n",
    "one_test('1 and 1 makes 2', 1 + 1, 2)\n",
    "one_test('1 and 1 makes 2', 1 + 1, 2, details = True)\n",
    "one_test('2 and 2 makes 4', 2 + 2, 5)\n",
    "one_test('2 and 2 makes 4', 2 + 2, 5, details = True)\n",
    "\n",
    "\n",
    "PARLIAMENT = 'parliament'\n",
    "ARIAN = 'arian'\n",
    "PARLIAMENTARIAN ='parliamentarian'\n",
    "\n",
    "set_P  = set(PARLIAMENT)\n",
    "set_A  = set(ARIAN)\n",
    "set_PA = set(PARLIAMENTARIAN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q1(a)(i) (1 mark)\n",
    "\n",
    "Run the following test to explore use of set operators.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "TYPE": "CODEBLOCK",
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_PA - set_P = set_A :  FAILED\n"
     ]
    }
   ],
   "source": [
    "one_test('set_PA - set_P = set_A : ',  set_PA - set_P, set_A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXTBLOCK",
    "deletable": false,
    "editable": false
   },
   "source": [
    "Given the way these sets were defined, you might have expected this test to pass. Explain briefly below why it fails. We want a general explanation, not a list of the elements of each set, for example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "MARKS": 1,
    "QUESTION": "1ai",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "source": [
    "Add your answer for Q1(a)(i) here: <br><br>\n",
    "The test will fail because set _PA is not equal to either set _P or Set_A. \n",
    "\n",
    "This problem can be further explained, if we were to subtract the word ARIAN from PARLIAMENT, this will mean that we are still left with the letter’s ‘A’, and ‘R’ (the letters A and R appear twice in the word PARLIAMENT). Additionally, the word ‘PARLIAMENTARIAN’ has the letter ‘A’ printed three times, which means ’set_A’ is not equal to either set.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q1(a)(ii) (2 marks)\n",
    "The tests below will also fail (run them to confirm this).  Edit the code below to change one operator in each test so that the tests pass. You should also change the operator in the test title (the first argument of the `one_test` function so that it matches your change to the test).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "MARKS": -1,
    "QUESTION": "1aii_",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_P  - set_A = set_PA:  FAILED\n",
      "set_PA - set_A = set_A :  FAILED\n"
     ]
    }
   ],
   "source": [
    "one_test('set_P  - set_A = set_PA: ',  set_P  - set_A, set_PA)\n",
    "one_test('set_PA - set_A = set_A : ',  set_PA - set_A, set_A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXTBLOCK",
    "deletable": false,
    "editable": false
   },
   "source": [
    "Explain below why each of your changed tests works. We want a general explanation, not a list of the elements of each set. You will get no marks here if you do not provide explanations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "MARKS": 2,
    "QUESTION": "1aii",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "source": [
    "Add your answer for Q1(a)(ii) here:<br>\n",
    "To pass the test use the code: one_test('set_P | set_A = set_PA: ', set_P | set_A, set_PA) one_test('set_PA & set_A = set_A : ', set_PA & set_A, set_A)\n",
    "\n",
    "To pass the first test, change the ‘Difference’ operator (-) to a ‘Union’ (|) operator; this will output the different sets without the duplicate letters.\n",
    "\n",
    "To pass the second test, change the ‘Difference’ operator (-) to an ‘Intersection’ (&) operator, this will output the sets which share letters that are common in both sets. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q1(b) (4 marks)\n",
    "\n",
    "The following code defines several bags whose members are individual characters, derived from character strings.  The bags are implemented using the Python Counter class.\n",
    "\n",
    "Run this code and then answer the questions in the section following the code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "TYPE": "CODEBLOCK",
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag_P union bag_A = bag_PA:  FAILED\n",
      "bag_PA intersection bag_A = bag_P:  FAILED\n",
      "bag_PA intersection bag_P = bag_A:  FAILED\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "bag_P  = Counter(PARLIAMENT)\n",
    "bag_A  = Counter(ARIAN)\n",
    "bag_PA = Counter(PARLIAMENTARIAN)\n",
    "\n",
    "one_test('bag_P union bag_A = bag_PA: ',  bag_P | bag_A, bag_PA)\n",
    "one_test('bag_PA intersection bag_A = bag_P: ',  bag_PA & bag_A, bag_P)\n",
    "one_test('bag_PA intersection bag_P = bag_A: ',  bag_PA & bag_P, bag_A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q1(b)(i) (2 marks)\n",
    "You should have found that all the tests in the previous code have failed.  Explain briefly below why this is so. We want a general explanation, not a list of the elements of each bag.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "MARKS": 2,
    "QUESTION": "1bi",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "source": [
    "Add your answer for Q1(b)(i) here:<br>\n",
    "The tests failed, because, in the first test, bag_P (PARLIAMENT) contains a different number (count) of the same letters than either bag_PA (PARLIAMENTARIAN) or bag_A (ARIAN). Additionally, bag_PA contains the letter ‘A’ four times while bag_P only contains the letter ‘A’ twice.<br><br> The second test also failed, because, it will return false as the count value doesn’t exist (is not the same) in both sets. Moreover, the set’ bag_P’ is different from set bag_A, because the letters in bag_P contains letters that are not present in bag_A. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q1(b)(ii) (2 marks)\n",
    "Edit the code below to change one operator in each test so that all the tests pass.  You should also change the test title (the first argument of the `one_test` function so that it matches your change to the test).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "MARKS": -1,
    "QUESTION": "1bii_",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag_P union bag_A = bag_PA:  OK\n",
      "bag_PA intersection bag_A = bag_P:  OK\n",
      "bag_PA difference bag_P = bag_A:  OK\n"
     ]
    }
   ],
   "source": [
    "one_test('bag_P union bag_A = bag_PA: ', bag_P + bag_A, bag_PA)\n",
    "one_test('bag_PA intersection bag_A = bag_P: ', bag_PA - bag_A, bag_P)\n",
    "one_test('bag_PA difference bag_P = bag_A: ', bag_PA - bag_P, bag_A) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXTBLOCK",
    "deletable": false,
    "editable": false
   },
   "source": [
    "Then explain below why your changed operations work correctly. We want a general explanation, not a list of the elements of each bag. You will get no marks here if you do not provide explanations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "MARKS": 2,
    "QUESTION": "1bii",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "source": [
    "Add your answer for Q1(b)(ii) here:<br><br>\n",
    "Changing the original operator from a union operator to an addition operator allows us to combine (concatenate) the elements of both bags, thus, ensuring that the two bags include all the unique elements which are needed to work.  <br><br>\n",
    "The second line of code was changed from the ‘intersection’ operator to a ‘difference’ operator, the difference operator subtracted the elements that were not present in both bags. <br><br>\n",
    "Lastly, in the original code we used the intersection operator for the test, by changing the operator to a ‘difference’ operator, the elements that were not present in both bags were subtracted.   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q1(c) (4 marks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q1(c)(i) (1 mark)\n",
    "Run the following code that tests the use of the `len` function on strings, sets and bags and explain below why the second and third tests  fail.  We want a general explanation, not a list or a count of the elements of each set or bag.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "TYPE": "CODEBLOCK",
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(PARLIAMENT) + len(ARIAN) == len(PARLIAMENTARIAN) :  OK\n",
      "len(set_P) + len(set_A) == len(set_PA) :  FAILED\n",
      "len(bag_P) + len(bag_A) == len(bag_PA) :  FAILED\n"
     ]
    }
   ],
   "source": [
    "one_test('len(PARLIAMENT) + len(ARIAN) == len(PARLIAMENTARIAN) : ',  len(PARLIAMENT) + len(ARIAN) == len(PARLIAMENTARIAN), True)\n",
    "one_test('len(set_P) + len(set_A) == len(set_PA) : ',  len(set_P) + len(set_A) == len(set_PA), True)\n",
    "one_test('len(bag_P) + len(bag_A) == len(bag_PA) : ',  len(bag_P) + len(bag_A) == len(bag_PA), True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "MARKS": 1,
    "QUESTION": "1ci",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "source": [
    "Enter your answer for Q1(c)(i) here<br><br>\n",
    "The first test will satisfy the condition because Strings are an ordered sequence of characters (Strings are sequence types).\n",
    "<br><br>\n",
    "The second test will fail because the ‘sets’ (a set is unordered with no duplicates) are unordered elements. Moreover, there are duplicates of letters in the words ‘Parliament’ and ‘Arian’ which will show the sum (‘Parliamentarians’) as ten. As a set is unordered with no duplicates it will return fail.<br><br> The third test will also fail, bags are also unordered but allow duplicates, which means that the words ‘Parliament’ and ‘Arian’ when combined will add up to 12 letters. This will result in a test fail.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q1(c)(ii) (3 marks)\n",
    "For a more useful measure of the size of a bag, we need a function to calculate how many items are in a bag, counting multiple occurrences of any characters that occur more than once.  Write a function called `size`, that does this and carry out a revised version of the bag length test above to check that it works.  Also add the code as indicated below to further test the `size` and `len` functions,\n",
    "\n",
    "Recent versions of Python have added a function like our `size` function to the `Counter` class, but you will only get marks here if you write your own function.\n",
    "\n",
    "The `Counter` class has a useful method `most_common` that can be used to find the `n` most common items in a bag and their multiplcities, for any positive integer `n`.  Run the following code for the standard documentation showing how to use this method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "TYPE": "CODEBLOCK",
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method most_common in module collections:\n",
      "\n",
      "most_common(n=None) method of collections.Counter instance\n",
      "    List the n most common elements and their counts from the most\n",
      "    common to the least.  If n is None, then list all element counts.\n",
      "    \n",
      "    >>> Counter('abracadabra').most_common(3)\n",
      "    [('a', 5), ('b', 2), ('r', 2)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(bag_A.most_common)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXTBLOCK",
    "deletable": false,
    "editable": false
   },
   "source": [
    "You may also want to look up this method online [here](https://docs.python.org/3/library/collections.html#collections.Counter) .  You will find it useful in the following exercise and also later in this question.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "MARKS": 3,
    "QUESTION": "1cii",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(bag_P) + size(bag_A) == size(bag_PA) :  OK\n",
      "Number of distinct characters: 16\n",
      "Total number of characters: 21\n",
      "5th most common character: o\n",
      "Frequency of occurrence: 1\n"
     ]
    }
   ],
   "source": [
    "def size(bag : Counter)-> int:\n",
    "    \"\"\" returns the total number of items in a bag \"\"\"\n",
    "    # Replace the following with your code\n",
    "    return sum(bag.values())\n",
    "    pass\n",
    "\n",
    "# Use this test to check if your `size` function works as expected\n",
    "one_test('size(bag_P) + size(bag_A) == size(bag_PA) : ',  size(bag_P) + size(bag_A) == size(bag_PA), True, details=True)\n",
    "\n",
    "def one_test(test_name, result, expected, details=False):\n",
    "    print(test_name)\n",
    "    if details:\n",
    "        print(f\"Result: {result}, Expected: {expected}\")\n",
    "    assert result == expected\n",
    "\n",
    "# Create a new bag here containing the characters of your full name and your OU PI, all in lower case with no spaces.\n",
    "pass   # replace this line  with your code\n",
    "namePI_bag = Counter(\"aaronbrucesmithabs247\")\n",
    "\n",
    "# Display the number of distinct characters and the total number of characters in your namePI bag (counting any multiple occurrences).\n",
    "pass   # replace this line with your code\n",
    "print(\"Number of distinct characters:\", len(namePI_bag))\n",
    "print(\"Total number of characters:\", size(namePI_bag))\n",
    "\n",
    "# Use the `Counter` method `most_common` to find and display the 5th most common character in your namePI bag and its frequency of occurrence.\n",
    "pass   # replace this line with your code\n",
    "common_chars = namePI_bag.most_common()\n",
    "if len(common_chars) >= 5:\n",
    "    fifth_common_char = common_chars[4]\n",
    "    print(\"5th most common character:\", fifth_common_char[0])\n",
    "    print(\"Frequency of occurrence:\", fifth_common_char[1])\n",
    "else:\n",
    "    print(\"Not enough characters for 5th most common.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q1(d) (11 marks)\n",
    "\n",
    "We want to be able to carry out an analysis of words in long documents to find the most frequently used words. This can be used for example to identify the most important words for language learning or to try to identify authors in literary works.   Later on we will ask you to analyse two Shakespeare plays, Hamlet and The Merchant of Venice, to find the 20 most frequent words and the number of times each word occurs.  Because the most common words are mainly stop words (articles, prepositions, etc.) and the play's characters (e.g. Hamlet, Horatio, Portia etc.) we will also want the ability to exclude certain words from the analysis.\n",
    "\n",
    "First we want to explore the problem in a more general abstract form.\n",
    "\n",
    "Given the name (string) of a text file containing words, a positive integer `m` and a text file containing excluded words (strings), find the `m` most frequent words in the file (apart from the excluded words) and their frequencies, given in descending order of frequency.\n",
    "\n",
    "We define this more formally, as follows:\n",
    "\n",
    "**Operation**: Most common in file\\\n",
    "**Inputs**: *filename*, a string; *excluded-words-filename*, a string; *m*, integer\\\n",
    "**Preconditions**: Files of names *filename* and *excluded-words-filename* are text files; *m* > 0\\\n",
    "**Outputs**: *most-common-words*, a list of at most *m* items, where each item is a tuple\\\n",
    "**Postconditions**: Each item of *most-common-words*, is a tuple containing a word from the file *filename* together with its frequency, with the list being in descending order of frequency, and no tuples for words from *excluded-words-filename* are in the list.\\\n",
    "The frequency component of each tuple in *most-common-words* is greater than or equal to the frequency of occurrence for any other words in *filename*, ignoring any words in *excluded-words-filename*.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q1(d)(i) (3 marks)\n",
    "The main ADT to use for storing the text should be a bag.  You will also need to choose a suitable ADT for the excluded words, and you can also use other standard simple built-in data structures of Python such as lists or strings, if necessary.\n",
    "\n",
    "State what sort of ADTs and data structures you would use for this problem and explain what is stored in these ADTs. Do not explain your choices at this stage - we will ask about that later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "MARKS": 3,
    "QUESTION": "1di",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "source": [
    "Add your answer for Q1(d)(i) here:<br><br>\n",
    "The ADT(s) and data structures I would use to solve this problem are as followed.\n",
    "\n",
    "(1) If I were to store word(s) from a text file, I would use the ADT entitled Bag, moreover, this process will allow each word within the text file to be added to the bag. Moreover, allowing the user to iterate through an array with its frequency represented by the number of occurrences; in this example the int variable 'm'.\n",
    "\n",
    "(2) If I were to use the most efficient ADT for checking whether a word or unique element should be excluded from an analysis I would use the ADT entitled set. I could therefore, store unique elements ensuring that each excluded word is only stored once. \n",
    "\n",
    "(3) I would use the Data Structure entitled Lists. Lists are an ordered collection of data or items. The Data Structure Lists will provide a simple way to maintain an ordered collection of items; which will allow the most common words and their frequencies to be stored. Moreover, the user can retrieve and manipulation items that are stored from the list. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q1(d)(ii) (3 marks)\n",
    "\n",
    "Give a step-by-step explanation, showing how your solution would work.\n",
    "\n",
    "You can make use of any of the bag ADT operations listed in Chapter 8.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "MARKS": 3,
    "QUESTION": "1dii",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "source": [
    "Write your answer to Q1(d)(ii) here\n",
    "\n",
    "The following steps are my explanation for the question ‘How would I implement the solution’.\n",
    "\n",
    "(1) Process the words from the text file provided. I would instruct the computer to read the contents of the text file and then create a bag to store the words from the text file along with their frequencies.\n",
    "\n",
    "(2) Sort the bag by frequency, I would create a set to store each of the words to the set of excluded words. The next step would to be to convert the bag into a list of tuples, where each tuple contains a word and its frequency. The user could iterate through the bag and then sort this list based on the frequency each tuple. \n",
    "\n",
    "(3) Lastly, retrieve the most common words and return the result. Take the first m from the sorted list, m being the most frequent words in the text file, return the list of m most common words along with their frequencies. In this example the user could take the first ‘m’ tuples from the List and return the result.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q1(d)(iii) (5 marks)\n",
    "Now explain your chosen approach by outlining the characteristics and the expected performance of the operations on bags and other ADTs/data structures you have used, in standard Python implementations. You should reference the performance discussions for bags in Chapter 8 and relevant performance discussions elsewhere in the module text for other ADTs/data structures.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "MARKS": 5,
    "QUESTION": "1diii",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "source": [
    "Write your answer to Q1(d)(iii) here \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q1(e) (12 marks)\n",
    "\n",
    "Implement your approach from part (d) to solve the abstract problem introduced in part (d) and extended somewhat here:\n",
    "\n",
    "Analyse two given literary texts to find the 20 most frequent words and the number of times each word occurs.  Exclude from the analysis the words that are often most common but less important to the analysis: so-called stop words (articles, prepositions, etc.) and words naming the text's characters. The original files for the two texts may contain line punctuation and extraneous characters at the start or end of words such as apostrophes, dashes etc and these should be removed before further processing. The excluded words relevant to each text are listed in a given text file - and this has been cleaned so that it just contains the relevant words, without any punctuation or extraneous characters.\n",
    "\n",
    "In this case the first text is Shakespeare's Hamlet (in the given text file ```hamlet.txt```) with excluded words listed in the given text file ```hamlet_excluded_words.txt```.  The second text is Shakespeare's Merchant of Venice (in the given text file ```merchant.txt```) with excluded words listed in the given text file ```merchant_excluded_words.txt```.\n",
    "\n",
    "We also want you to find the words that occur in both these texts and the number of occurrences in common for these words  e.g. if `dog` occurs 10 times in the first text and 25 times in the second text, then there are 10 occurrences in common.\n",
    "\n",
    "We have provided code frameworks for your solution below. We have split the problem and the code framework into two parts so you can do one bit at a time and check each part is working.\n",
    "\n",
    "The first framework includes functions that handle reading data from files into lists and \"cleaning\" data to remove punctuation when necessary, as file handling is not covered in M269.\n",
    "\n",
    "Remember that you can only use the Python data types, methods and functions listed in the chapter summaries, unless specified otherwise in this TMA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q1(e)(i) (5 marks)\n",
    "The first part of the problem requires reading a text from a file, eliminating excluded words, and storing the results in a bag.\n",
    "\n",
    "As in part(d), we define this more formally, as follows:\n",
    "\n",
    "**Operation**: Get bag from file\\\n",
    "**Inputs**: *filename*, a string; *excluded-words-filename* \\\n",
    "**Preconditions**: Files of names *filename* and *excluded-words-filename* are text files\\\n",
    "**Outputs**: *text*, a bag of words\\\n",
    "**Postconditions**: The bag *text* contains all words from the file *filename* together with their frequency of occurrence, except that any words from *excluded-words-filename* are omitted.\n",
    "\n",
    "Here is the code framework for this first part of the problem.  We have included some simple test code, to let you check if your code seems to be working so far.\n",
    "\n",
    "Please make the required changes as indicated by comments. When you have finished run your code to view the output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "MARKS": 5,
    "QUESTION": "1ei",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting words in text...\n",
      "Size of text FAILED: 1 instead of 20635\n",
      "Tests finished.\n",
      "Most common word in text FAILED: [('project', 1)] instead of [('lord', 223)]\n",
      "Tests finished.\n"
     ]
    }
   ],
   "source": [
    "# Change this code in the places indicated\n",
    "# in order to implement and test your solution\n",
    "\n",
    "%run -i m269_util\n",
    "\n",
    "# Import the functions read_file and read_and_clean_file\n",
    "%run -i m269_tma03_filehandling\n",
    "\n",
    "\n",
    "#  You will need to amend this function so that the excluded\n",
    "#  words extracted from the list are added to the data structure\n",
    "#  that is returned. You should also set the type annotation\n",
    "#  for the function return value\n",
    "\n",
    "def get_excluded_words(word_list : list) :\n",
    "    \"\"\"Returns the excluded words occurring in word_list\n",
    "       in a suitable data structure.  Here we use a set.\n",
    "    \"\"\"\n",
    "    #  replace the following with your code to initialise the data structure\n",
    "    words = set()\n",
    "    #words = None\n",
    "\n",
    "    #  replace the following with your code to add words from the list if not blank\n",
    "    for item in word_list:\n",
    "        if item.strip() ==\"\":\n",
    "            continue\n",
    "        words.add(item.strip())\n",
    "        return words\n",
    "\n",
    "\n",
    "#  You will need to amend this function so that the words from the list are\n",
    "#  added to the data structure that is returned, apart from the excluded words.\n",
    "#  You should also set the type annotations for the excluded_words argument\n",
    "\n",
    "def bag_of_words(word_list : list, excluded_words)-> Counter:\n",
    "    \"\"\"Return the words occurring in word_list as a bag-of-words,\n",
    "       omitting any excluded words\n",
    "    \"\"\"\n",
    "    words = Counter()\n",
    "\n",
    "    #  replace the following with your code to add words from the list if not\n",
    "    #  an excluded word\n",
    "    \n",
    "    for word in word_list:\n",
    "        if not word in words:\n",
    "            words[word.strip()] +=1\n",
    "            return words\n",
    "\n",
    "\n",
    "# You should not need to change this function\n",
    "def get_bag_from_file(filename : str, excluded_words_file : str) -> Counter:\n",
    "    \"\"\" Return list of \"m\" most frequent words and their percentage frequencies\n",
    "        in the text of file \"filename\", excluding all the words in file \"excluded_words\"\n",
    "    \"\"\"\n",
    "    excluded_words_list= read_file(excluded_words_file)\n",
    "    excluded_words = get_excluded_words(excluded_words_list)\n",
    "\n",
    "    text_list = read_and_clean_file(filename)\n",
    "\n",
    "    text = bag_of_words(text_list, excluded_words)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# We have provided the following code here to allow you to check if your\n",
    "# code is working so far.  You should not need to change it unless you wish\n",
    "# to add more tests of your own.\n",
    "\n",
    "print(\"Collecting words in text...\")\n",
    "\n",
    "text = get_bag_from_file('hamlet.txt', 'hamlet_excluded_words.txt')\n",
    "\n",
    "test(size, [['Size of text', text, 20635 ]])\n",
    "test(text.most_common, [['Most common word in text', 1, [('lord', 223)] ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q1(e)(ii) (7 marks)\n",
    "The second part of the problem requires reading both texts from files, eliminating excluded words, and storing the results in bags, finding the overlap between the texts and displaying the top 20 most common words and their **relative frequencies** from each text.\n",
    "\n",
    "[Note the slight refinement from the part (d) problem to use relative rather than absolute frequencies.  The absolute frequency is an integer representing the number of times a word appears in a text.  The relative frequency is a fraction or decimal number, found by dividing the absolute frequency by the total number of words in the text.  This should be a more useful way to compare texts that will usually differ in their total numbers of words.]\n",
    "\n",
    "As in part(d), we define the key function more formally, as follows:\n",
    "\n",
    "**Operation**: Most common words\\\n",
    "**Inputs**: *text*, a bag of words; *m*, integer\\\n",
    "**Preconditions**: *m* > 0\\\n",
    "**Outputs**: *most-common-words*, a list of at most *m* items, where each item is a tuple\\\n",
    "**Postconditions**: Each item of *most-common-words*, is a tuple containing a word from the bag *text*, with its relative frequency in the bag, given as a percentage rounded to 3 decimal places. &emsp;The relative frequency component of each tuple in *most-common-words* is greater than or equal to the relative frequency for any other words in the bag *text*.\n",
    "\n",
    "Here is the code framework for this second part the  problem.  We have included some test code, to let you check if your code seems to be working properly.\n",
    "\n",
    "Please make the required changes as indicated by comments. When you have finished run your code to view the output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "MARKS": 7,
    "QUESTION": "1eii",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the top 20 most frequent words in first text ...\n",
      "Done\n",
      "Finding the top 20 most frequent words in second text ...\n",
      "Done\n",
      "Finding the top 20 most frequent words in third (overlap) text ...\n",
      "Done\n",
      "Tests finished.\n",
      "Tests finished.\n",
      "Tests finished.\n",
      "\n",
      "The 20 most frequent words and their percentage frequencies are:\n",
      "First text        |    Second text       |    In Both\n",
      "===============================================================\n",
      "lord        1.081 |    have        1.207 |    have        1.807\n",
      "king        0.950 |    will        0.982 |    will        1.470\n",
      "have        0.906 |    do          0.858 |    do          1.285\n",
      "will        0.858 |    shall       0.778 |    shall       1.165\n",
      "do          0.809 |    thou        0.749 |    thou        1.122\n",
      "all         0.669 |    all         0.647 |    all         0.969\n",
      "queen       0.582 |    well        0.589 |    well        0.828\n",
      "o           0.582 |    am          0.553 |    at          0.795\n",
      "shall       0.562 |    at          0.531 |    would       0.795\n",
      "good        0.528 |    would       0.531 |    her         0.740\n",
      "come        0.514 |    her         0.495 |    let         0.730\n",
      "they        0.514 |    let         0.487 |    come        0.708\n",
      "thou        0.509 |    here        0.487 |    more        0.686\n",
      "at          0.485 |    than        0.473 |    good        0.686\n",
      "more        0.480 |    come        0.473 |    then        0.686\n",
      "now         0.480 |    thee        0.473 |    which       0.675\n",
      "let         0.465 |    then        0.465 |    how         0.642\n",
      "how         0.456 |    more        0.458 |    thy         0.642\n",
      "her         0.441 |    good        0.458 |    love        0.642\n",
      "project     0.431 |    which       0.451 |    thee        0.632\n"
     ]
    }
   ],
   "source": [
    "# Change this code in the places indicated\n",
    "# in order to implement and test your solution\n",
    "%run -i m269_util\n",
    "\n",
    "# Import the functions read_file and read_and_clean_file\n",
    "%run -i m269_tma03_filehandling\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "#Method from part 1\n",
    "def size(bag: Counter) -> int:\n",
    "    return sum(bag.values())\n",
    "\n",
    "def get_excluded_words(word_list : list) :\n",
    "    \"\"\"Returns the excluded words occurring in word_list\n",
    "       in a suitable data structure.  Here we use a set.\n",
    "    \"\"\"\n",
    "    words = set()\n",
    "    for word in word_list:\n",
    "        if word.strip():\n",
    "            words.add(word)\n",
    "            \n",
    "    return words\n",
    "    \n",
    "def bag_of_words(word_list : list, excluded_words)-> Counter:\n",
    "    \"\"\"Return the words occurring in word_list as a bag-of-words,\n",
    "       omitting any excluded words\n",
    "    \"\"\"\n",
    "    words = Counter()\n",
    "\n",
    "    #  replace the following with your code to add words from the list if not\n",
    "    #  an excluded word\n",
    "    \n",
    "    for word in word_list:\n",
    "        if word not in excluded_words:\n",
    "            words[word] +=1\n",
    "    \n",
    "    return words\n",
    "\n",
    "    \n",
    "def get_bag_from_file(filename : str, excluded_words_file : str) -> Counter:\n",
    "    \"\"\" Return list of \"m\" most frequent words and their percentage frequencies\n",
    "        in the text of file \"filename\", excluding all the words in file \"excluded_words\"\n",
    "    \"\"\"\n",
    "    excluded_words_list= read_file(excluded_words_file)\n",
    "    excluded_words = get_excluded_words(excluded_words_list)\n",
    "\n",
    "    text_list = read_and_clean_file(filename)\n",
    "\n",
    "    text = bag_of_words(text_list, excluded_words)\n",
    "\n",
    "    return text\n",
    "\n",
    "# You should not have to change this function\n",
    "def relative_frequencies(words_freq : list,  text_size : int) -> list:\n",
    "    \"\"\" Convert the list of (word, absolute frequency) pairs in a text to relative\n",
    "        frequencies in percentages, rounded to 3 decimal places\n",
    "    \"\"\"\n",
    "    relative_frequency = []\n",
    "    for w in range(0, len(words_freq)):\n",
    "        relative_frequency.append( (words_freq[w][0], round((100*words_freq[w][1])/text_size, 3)) )\n",
    "\n",
    "    return relative_frequency\n",
    "\n",
    "\n",
    "# Complete the missing parts of this function where indicated by comments\n",
    "def most_common_words(text : Counter, m : int) -> list:\n",
    "    \"\"\" Return list of \"m\" most frequent words and their percentage frequencies\n",
    "        in the text of file \"filename\", excluding all the words in file \"excluded_words\"\n",
    "    \"\"\"\n",
    "    # Find total number of words in the text\n",
    "    # Replace the following line with your code\n",
    "    text_size = size(text)\n",
    "\n",
    "    # Find the \"m\" most common words and their absolute frequencies\n",
    "    # Replace the following line with your code\n",
    "    frequency = text.most_common(m)\n",
    "\n",
    "    # Convert the list of words and absolute frequencies to relative frequencies in percentages\n",
    "    # Replace the following line with your code\n",
    "    relative_frequency = relative_frequencies(frequency, text_size)\n",
    "\n",
    "    return relative_frequency\n",
    "\n",
    "\n",
    "# You should not have to change this function\n",
    "def print_table(m : int, frequency_1 : list, frequency_2 : list, frequency_3 : list) -> None:\n",
    "    \"\"\" Print formatted table of 'm' most frequent words and their percentage frequencies\n",
    "        in each of three lists containing (word, frequency) pairs.\n",
    "        If there are fewer than \"m\" items in any of the lists then the table will have the\n",
    "        same number of rows as the length of the smallest list\n",
    "    \"\"\"\n",
    "    n = min(m, len(frequency_1), len(frequency_2), len(frequency_3))\n",
    "    print()\n",
    "    print(\"The\", n, \"most frequent words and their percentage frequencies are:\")\n",
    "    print('First text        |    Second text       |    In Both')\n",
    "    print('===============================================================')\n",
    "\n",
    "    for i in range(0, n):\n",
    "        print(f'{frequency_1[i][0]:10} {(frequency_1[i][1]):6.3f} |\\\n",
    "    {frequency_2[i][0]:10} {(frequency_2[i][1]):6.3f} |\\\n",
    "    {frequency_3[i][0]:10} {(frequency_3[i][1]):6.3f}')\n",
    "\n",
    "\n",
    "TOP = 20\n",
    "print('Finding the top', TOP, 'most frequent words in first text ...')\n",
    "# Replace the following two lines with your code\n",
    "text_1 = get_bag_from_file('hamlet.txt', 'hamlet_excluded_words.txt')\n",
    "frequency_1 = most_common_words(text_1, TOP)\n",
    "print(\"Done\")\n",
    "\n",
    "print('Finding the top', TOP, 'most frequent words in second text ...')\n",
    "# Replace the following two lines with your code\n",
    "text_2 = get_bag_from_file('merchant.txt', 'merchant_excluded_words.txt')\n",
    "frequency_2 = most_common_words(text_2, TOP)\n",
    "print(\"Done\")\n",
    "\n",
    "\n",
    "# Find words occurring in both texts and the number of occurrences in common\n",
    "# Replace the following line with your code\n",
    "text_3 = text_1 & text_2\n",
    "\n",
    "print('Finding the top', TOP, 'most frequent words in third (overlap) text ...')\n",
    "# Replace the following line with your code\n",
    "frequency_3 = most_common_words(text_3, TOP)\n",
    "print(\"Done\")\n",
    "\n",
    "#  Run tests for first 3 words from each text\n",
    "test(most_common_words, [['Most common text_1', text_1, 3,\n",
    "                        [('lord', 1.081), ('king', 0.950), ('have', 0.906)] ]])\n",
    "test(most_common_words, [['Most common text_2', text_2, 3,\n",
    "                        [('have', 1.207), ('will', 0.982 ), ('do', 0.858)] ]])\n",
    "test(most_common_words, [['Most common text_3', text_3, 3,\n",
    "                        [('have', 1.807), ('will', 1.470 ), ('do', 1.285)] ]])\n",
    "\n",
    "print_table(TOP, frequency_1, frequency_2, frequency_3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2 (26 marks)\n",
    "\n",
    "You should be able to answer this question after you have studied Chapter 18.\n",
    "\n",
    "This question tests the following learning outcomes:\n",
    "\n",
    "- Develop and apply algorithms and data structures to solve computational problems.\n",
    "- Explain how an algorithm or data structure works, in order to communicate with relevant stakeholders.\n",
    "- Analyse the complexity of algorithms to support software design choices.\n",
    "- Write readable, tested, documented and efficient Python code.\n",
    "\n",
    "**Graphs** are explained in Chapters 17 and 18 and we will make use of some of the Python code provided there to implement graphs.\n",
    "We will revisit the context of the previous question &ndash; analysis of the words in long documents. However, in this case, instead of ordering by frequency we wish to consider connections between words, in particular the occurrence of pairs of words in a particular order.  Such ordered groups of words are known as **bigrams** for two words, trigrams for three words, and in general `n`-grams for an ordered sequence of `n` words.\n",
    "\n",
    "The table in Chapter 17 Section 17.2.4 shows the operations defined for unweighted graph ADTs, both directed and undirected.  The ADT for weighted graphs is similar but with some differences, as explained in Chapter 18 Section 18.2.2.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q2(a) (11 marks)\n",
    "\n",
    "We want to be able to carry out an analysis of the relationships between words in long documents.  This can be useful in studies of literary style, identifying likely authors of texts for example.\n",
    "\n",
    "Later on we will ask you to apply this analysis to Shakespeare's Hamlet. For this question, we will assume that **the file has been cleaned** to remove all line punctuation and other unnecessary leading or trailing characters such as quote marks from the words.\n",
    "\n",
    "First we want to explore the problem in a more general abstract form.\n",
    "\n",
    "Given the name (string) of a text file containing words, store the words in such a way as to record which words precede or follow other words. Analyse this stored data to identify the `m` most common ordered pairs of words (bigrams) where `m` is an integer value.  We define this more formally, as follows:\n",
    "\n",
    "**Operation**: Most common bigrams\\\n",
    "**Inputs**: *filename*, a string; *m*, integer\\\n",
    "**Preconditions**: File of name *filename* is a text file; *m* > 0\\\n",
    "**Outputs**: *most-common*, a list of at most *m* items, where each item is a triple\\\n",
    "**Postconditions**:  Each item of *most-common*, is a triple containing the two words of a bigram from the file, together with its frequency, with the list being in descending order of frequency.\n",
    "The frequencies of all items in *most-common* are greater than or equal to the frequencies of all other bigrams in *filename*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q2(a)(i) (4 marks)\n",
    "The ADT you use should be some kind of graph, though you can use other standard simple built-in data structures of Python such as lists or strings, if necessary.\n",
    "\n",
    "State what sort of graph ADT you would use for this problem (directed/undirected, weighted/unweighted).  Explain what is represented by the features of the graph, such as its nodes and edges, and why this is a suitable choice.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "MARKS": 4,
    "QUESTION": "2ai",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "source": [
    "Write your answer to Q2(a)(i) here<br><br>\n",
    "I would use a directed and weighted approach to solving the ADT graph, a directed graph will show the relationship between words in an unidirectional way (when each word increments). Additionally, the weighted graph is used to track the frequency of each node using the shortest path. Moreover, I would use a node to represent each [unique] word from the input text file, each edge will represent the connection between the nodes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q2(a)(ii) (3 marks)\n",
    "\n",
    "Give a step-by-step explanation, showing how your solution would work.\n",
    "\n",
    "You can make use of any of the graph ADT operations from Chapters 17 and 18.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "MARKS": 3,
    "QUESTION": "2aii",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "source": [
    "Write your answer to Q2(a)(ii) here<br><br>\n",
    "(1) Read the text file:<br>\n",
    "(2) Create Nodes: Create a node for each unique word in the text file.<br>\n",
    "(3) Create Edges: For each pair of consective words in the text file, create a directed edge from the node representing the first word to the node representing the second node. <br>\n",
    "(4) Update Edge Weights: increment the weight of the edge reprenting the bigram by 1.<br>\n",
    "(5) Filter Low-Frequency Bigrams: removing any bigrams with a frequency below a specified threshold. <br>\n",
    "(6) Sort Edges: sort the edges in decending order of their weights.<br>\n",
    "(7) Extract Most Common Bigrams: extract the top 'm' edges (where 'm' is a specified integer) to obtain the most common bigrams.<br> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q2(a)(iii) (4 marks)\n",
    "Now outline the expected performance of the operations on graphs and other data structures you may have used, in standard Python implementations.  You should explain which graph representation (edge list/adjacency matrix/adjacency list) you would use, and reference the performance discussions for graphs in Chapters 17 and 18.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "MARKS": 4,
    "QUESTION": "2aiii",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "source": [
    "Write your answer to Q2(a)(iii) here\n",
    "<br>\n",
    "<table style=\"width:100%; background-color: #f2f2f2;\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th scope=\"col\">Operation</th>\n",
    "            <th scope=\"col\">Implementation</th>\n",
    "            <th scope=\"col\">Complexity</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Reading text file</td>\n",
    "            <td>Python build in functions (open())</td>\n",
    "            <td>O(n)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Create Nodes and Edges</td>\n",
    "            <td>Iteration</td>\n",
    "            <td>O(1) per node or edge</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Updating Edge Weights</td>\n",
    "            <td>Increment the weight of an edge</td>\n",
    "            <td>O(1)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Filtering Low-Frequency Bigrams</td>\n",
    "            <td>Iterate over edges</td>\n",
    "            <td>O(n), where n is the number of edges</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Sorting Edges</td>\n",
    "            <td>Python's build-in sorting algorithms</td>\n",
    "            <td>O(n log n)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Extracting Most Common Bigrams</td>\n",
    "            <td>Selecting top 'm' edges</td>\n",
    "            <td>O(m)</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q2(b) (10 marks)\n",
    "\n",
    "Implement your approach from part (a) to solve the problem introduced in part (a) and repeated again here, but applied to a specific text:\n",
    "\n",
    "Analyse Shakespeare's Hamlet (in the given text file `cleaned_hamlet.txt`) to\n",
    "store all the words in a graph that records which words precede or follow other words. Analyse this graph to identify and display the 20 most common ordered pairs of words (bigrams). You can assume that all punctuation and unnecessary leading and trailing characters (such as quote marks) as well as the very common words have already been removed.\n",
    "\n",
    "We have provided a framework for your solution below, with comments indicating where you will need to make changes.\n",
    "\n",
    "Remember that you can only use the Python data types, methods and functions listed in the chapters' summaries unless specifically mentioned in this TMA.\n",
    "\n",
    "You should make use of relevant parts of the code demonstrated in Chapters 17 and 18 for the of graph ADTs - the code for directed and undirected graphs (both weighted and unweighted) are within the included files.\n",
    "\n",
    "**The files `m269_ungraph.py`, `m269_digraph.py`, `m269_tma03_filehandling.py` and `m269_util.py` should be in the folder with this TMA notebook.**\n",
    "\n",
    "To make things easier we provide the framework code in two parts - first the framework for setting up the graph representing the words in the document, then the framework for the rest of the problem - finding and displaying the most common bigrams.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q2(b)(i) (5 marks)\n",
    "Here is the first part - setting up the graph. When you have made the required changes run your code and check that the printed output seems reasonable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "MARKS": 5,
    "QUESTION": "2bi",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "File `'m269_digraph.py'` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[0;32m    713\u001b[0m             \u001b[0mfpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_lst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_finder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    715\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\utils\\path.py\u001b[0m in \u001b[0;36mget_py_filename\u001b[1;34m(name, force_win32)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'File `%r` not found.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: File `'m269_digraph.py'` not found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\m269_tma03_filehandling.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'run'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-i m269_digraph'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'run'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-i m269_ungraph'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'run'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-i m269_util'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Import the function read_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2362\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2363\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2364\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2365\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[0;32m    723\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nt'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"^'.*'$\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m                 \u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'For Windows, use double quotes to wrap a filename: %run \"mypath\\\\myfile.py\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: File `'m269_digraph.py'` not found."
     ]
    }
   ],
   "source": [
    "\n",
    "%run -i m269_digraph\n",
    "%run -i m269_ungraph\n",
    "%run -i m269_util\n",
    "\n",
    "# Import the function read_file\n",
    "%run -i m269_tma03_filehandling\n",
    "\n",
    "\"\"\"\n",
    "You will need to amend this function so that it adds the words from the text\n",
    "file to a graph in the form of nodes and edges.  You should also set the\n",
    "return type appropriately.\n",
    "\"\"\"\n",
    "\n",
    "def graph_of_words(word_list : list):\n",
    "    \"\"\"Return the words occurring in word_list as a graph\n",
    "    \"\"\"\n",
    "    # replace the right hand side of this statement with an appropriate initialisation\n",
    "    words = None\n",
    "\n",
    "    # Add your code for this function here\n",
    "\n",
    "    return words\n",
    "\n",
    "\n",
    "print(\"Collecting words in Shakespeare's Hamlet...\")\n",
    "\n",
    "word_list = read_file('cleaned_hamlet.txt')\n",
    "\n",
    "word_graph = graph_of_words(word_list)\n",
    "\n",
    "print(\"Printing the graph of words\")\n",
    "#  Replace the following line with your code to display the contents\n",
    "# of the graph without any attempt to reorder it\n",
    "pass\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q2(b)(ii) (5 marks)\n",
    "Here is the second part - finding and displaying the `m` most common bigrams in the graph from part (b)(i).  We have provided some tests to show you if your first few results are as expected.\n",
    "\n",
    "When you have made the required changes run your code, check that it passes the tests and that the printed output seems reasonable.\n",
    "\n",
    "If your code does work properly you might want to try it on other documents but this is optional and not required for this TMA.  We found the texts used in this TMA at [Project Gutenberg](https://www.gutenberg.org/) which has many free and out-of-copyright great works of literature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "MARKS": 5,
    "QUESTION": "2bii",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting words in Shakespeare's Hamlet...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'graph_of_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\m269_tma03_filehandling.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 ]\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmost_common_bigrams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mTOP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\m269_tma03_filehandling.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(function, test_table)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_case\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mexpected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_case\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mactual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mactual\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mexpected\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'FAILED:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'instead of'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\m269_tma03_filehandling.py\u001b[0m in \u001b[0;36mmost_common_bigrams\u001b[1;34m(filename, m)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mword_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mword_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_of_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Replace the following two lines of code with your code to extract from the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'graph_of_words' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "You will need to complete this function so that it adds the words from the text\n",
    "file to a graph in the form of nodes and edges.  You should also set the\n",
    "return type appropriately.\n",
    "\"\"\"\n",
    "\n",
    "def most_common_bigrams(filename : str, m : int)-> list:\n",
    "    \"\"\" returns the 'm' most common bigrams and their frequencies in file 'filename'\n",
    "    \"\"\"\n",
    "    # We have provided the function 'read_file' to read the text file into\n",
    "    # a list of words, with each word as a separate string item in the list.\n",
    "    # File handling is not covered in M269\n",
    "    word_list = read_file(filename)\n",
    "\n",
    "    word_graph = graph_of_words(word_list)\n",
    "\n",
    "    # Replace the following two lines of code with your code to extract from the\n",
    "    # graph and return the 'm' most common bigrams and their frequencies,\n",
    "    # in descending order of frequency\n",
    "    pass\n",
    "\n",
    "    return []\n",
    "\n",
    "\n",
    "\n",
    "print(\"Collecting words in Shakespeare's Hamlet...\")\n",
    "\n",
    "# The following code tests if your first few results are as expected.\n",
    "# You should not need to change these unless you decide to add more tests\n",
    "# They follow the test table approach used in the module text\n",
    "\n",
    "expected_results = [\n",
    "                   ('first', 'clown', 33),\n",
    "                   ('good', 'lord', 23),\n",
    "                   ('1', 'e', 22),\n",
    "                   ('room', 'castle', 20),\n",
    "                   ('project', 'electronic', 18)\n",
    "                   ]\n",
    "\n",
    "test_table =    [\n",
    "                ['Most common bigram', 'cleaned_hamlet.txt', 1, expected_results[:1]],\n",
    "                ['Top 3 bigrams',      'cleaned_hamlet.txt', 3, expected_results[:3]],\n",
    "                ['Top 5 bigrams',      'cleaned_hamlet.txt', 5, expected_results[:5]]\n",
    "                ]\n",
    "\n",
    "test(most_common_bigrams, test_table)\n",
    "\n",
    "TOP = 20\n",
    "\n",
    "#  Replace the following line with your code to find the 20 most common\n",
    "#  bigrams and their frequencies.\n",
    "results = []\n",
    "\n",
    "print(\"Printing top\", len(results), \"bigrams by frequency\")\n",
    "#  Replace the following line with your code to display up to 20 of the most common\n",
    "#  bigrams and their frequencies, in an appropriate format.\n",
    "pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q(2)(c) (5 marks)\n",
    "\n",
    "We have asked you to use a graph to model the text, so as to solve the specified problem, but perhaps it may not be an appropriate solution?   Discuss the following questions. For guidance we would expect a maximum of three sentences per question.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q2(c)(i) (3 marks)\n",
    "\n",
    "Could you have used a tree instead of a graph to model the text or to solve the given problem?   If so, what sort of tree would be appropriate or if not, explain why not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "MARKS": 3,
    "QUESTION": "2ci",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "source": [
    "Write your answer to Q2(c)(i) here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q2(c)(ii) (2 marks)\n",
    "\n",
    "Would your approach using a graph extend from finding most common bigrams (two words) to finding most common trigrams (three words) or longer groups of words (n-grams)?  Explain why this extended approach would or would not be appropriate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "MARKS": 2,
    "QUESTION": "2cii",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "source": [
    "Write your answer to Q2(c)(ii) here.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "## PART 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3 (9 marks)\n",
    "\n",
    "You should be able to answer this question after you have studied Chapter 26.\n",
    "\n",
    "This question tests the following learning outcomes:\n",
    "\n",
    "- Understand the main complexity classes.\n",
    "\n",
    "A government agency is investigating a potential case of fraud\n",
    "across several companies. The agency creates an undirected graph where\n",
    "the nodes represent the current employees from all companies involved.\n",
    "From analysis of LinkedIn and other social media, the agency creates\n",
    "an edge between two people if they work for different companies now,\n",
    "but have worked for the same company in the past or\n",
    "have some other relationship, e.g. are friends or relatives.\n",
    "To start the investigation, the agency wants to find a group of\n",
    "mutually connected people. Because of the way edges are created,\n",
    "those people all work in different companies but know each other and\n",
    "so the agency suspects them of coordinating the fraud across the companies.\n",
    "\n",
    "For this question, consider the following variant of the agency's problem.\n",
    "\n",
    "**Function:** collusion\\\n",
    "**Inputs:** _people_, an undirected graph; _size_, an integer\\\n",
    "**Preconditions:** _people_ has _n_ ≥ 2 nodes; 2 ≤ _size_ ≤ _n_\\\n",
    "**Output:** _colluded_, a Boolean\\\n",
    "**Postconditions:** _colluded_ is true if and only if\n",
    "_people_ has _size_ nodes connected to each other\n",
    "\n",
    "Here is an example graph.\n",
    "\n",
    "![This figure shows a graph with five nodes, labelled A to E.\n",
    "There are six undirected and unweighted edges:\n",
    "A–B, B–C, C–E, E–D, D–A and D–B.](TMA03_Q3_graph.png)\n",
    "\n",
    "For _size_ = 2 the output is true,\n",
    "because several pairs of nodes (e.g. E and C) are connected.\n",
    "For _size_ = 3 the output is also true\n",
    "because nodes A, B and D are connected to each other.\n",
    "For _size_ ≥ 4 the output is false.\n",
    "No four (or more) nodes are mutually connected.\n",
    "For example, A, B, C and D aren't mutually connected because\n",
    "edges A–C and C–D are missing.\n",
    "\n",
    "Prove that this decision problem is in class NP by answering the following parts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q3(a) (5 marks)\n",
    "Describe a certificate for a problem instance\n",
    "(a graph _people_ and an integer _size_) that has a true output.\n",
    "Give as example the certificate for the graph above and _size_ = 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "MARKS": 5,
    "QUESTION": "3a",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "source": [
    "*Write your answer to Q3(a) here.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q3(b) (4 marks)\n",
    "EExplain why certificates for this problem can be verified in polynomial time.\n",
    "\n",
    "In other words, briefly explain what the verifier does,\n",
    "given _people_, _size_ and the corresponding certificate,\n",
    "and why it takes polynomial time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "MARKS": 4,
    "QUESTION": "3b",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "source": [
    "*Write your answer to Q3(b) here.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4 (8 marks)\n",
    "\n",
    "You should be able to answer this question after you have studied Chapter 26.\n",
    "\n",
    "This question tests the following learning outcomes:\n",
    "\n",
    "- Understand the common algorithmic techniques and complexity classes.\n",
    "\n",
    "Consider the problem _IsSet_ of deciding if a list of integers represents a set.\n",
    "For example, the output is true for `[]`, `[5]` and `[4, 20, -2, 567, 0]`,\n",
    "because they represent sets, and false for `[5, 0, 5, -1]`\n",
    "because the items in this list aren't unique.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q4(a) (5 marks)\n",
    "Outline a reduction algorithm that reduces _IsSet_ to\n",
    "a problem _Solved_ of your choice.\n",
    "Make sure your outline states what problem _Solved_ is,\n",
    "what inputs and output it has, and\n",
    "what the input and output transformations do.\n",
    "\n",
    "You may include a diagram, drawn by hand or with a computer,\n",
    "if it helps your explanation.\n",
    "To do that, put the PNG or JPEG file with your diagram in this folder and\n",
    "write `![](...)` in the Markdown cell, where ... is the filename,\n",
    "e.g. `reduction.jpg`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "MARKS": 5,
    "QUESTION": "4a",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "source": [
    "_Write your answer to Q4(a) here._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q4(b) (3 marks)\n",
    "Let's assume that your transformations take polynomial time and that\n",
    "you have additional information that _IsSet_ is tractable.\n",
    "Do these two pieces of information and your reduction prove that\n",
    "problem _Solved_ is also tractable? Explain why or why not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "MARKS": 3,
    "QUESTION": "4b",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "source": [
    "*Write your answer to Q4(b) here.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 5 (23 marks)\n",
    "You should be able to answer this question after you have studied Chapter 27.\n",
    "\n",
    "This question tests the following learning outcomes:\n",
    "\n",
    "- Understand the Turing Machine model of computation.\n",
    "- Explain how an algorithm or data structure works, in order to communicate with relevant stakeholders.\n",
    "\n",
    "We want a Turing machine that capitalises a string:\n",
    "the first letter of every word is changed to uppercase.\n",
    "\n",
    "There can only be six different symbols on the tape:\n",
    "`a`, `A` , `0`, `\"` (double quote), space and `None` (blank symbol).\n",
    "The input tape consists of a double quote, followed by zero or more spaces,\n",
    "`a`, `A` and `0`, followed by a double quote. The rest of the tape is blank.\n",
    "\n",
    "When the Turing machine stops, every `a` at the start of the string or\n",
    "preceded by a space has been replaced with `A`.\n",
    "The rest of the string must remain unchanged.\n",
    "For example, if the tape is initially\n",
    "```\n",
    "['\"', 'a', 'A', ' ', '0', 'a', ' ', 'a', 'a', '\"']\n",
    "```\n",
    "then the final tape is\n",
    "```\n",
    "['\"', 'A', 'A', ' ', '0', 'a', ' ', 'A', 'a', '\"']\n",
    "```\n",
    "The head begins and must end on the first (left-most) double quote.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q5(a) (15 marks)\n",
    "Write the transition table for the Turing machine.\n",
    "Use descriptive state names.\n",
    "\n",
    "The `list` constructor used in the test below was introduced in\n",
    "Section 4.6.2: `list('\"A\"')` evaluates to `['\"', 'A', '\"']`.\n",
    "Feel free to add your own tests to check your Turing machine, but\n",
    "you won't be awarded any marks for your tests.\n",
    "You don't have to remove your tests before submitting this TMA.\n",
    "\n",
    "Set the debug parameter to `True` if you want to see the configurations\n",
    "your Turing machine goes through.\n",
    "Make sure you **set it back to `False` before submitting** your TMA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "MARKS": 15,
    "QUESTION": "5a",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "outputs": [],
   "source": [
    "%run -i m269_util\n",
    "%run -i m269_tm\n",
    "\n",
    "capitalise = {\n",
    "    # Write the transitions here in the form\n",
    "    # (state, symbol): (new_symbol, LEFT or RIGHT or STAY, new_state),\n",
    "}\n",
    "\n",
    "capitalise_tests = [\n",
    "    # case,     TM,         input tape,         debug,  output tape\n",
    "    ('example', capitalise, list('\"aA 0a aa\"'), False,  list('\"AA 0a Aa\"')),\n",
    "]\n",
    "\n",
    "test(run_TM, capitalise_tests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXT",
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Q5 (b) (8 marks)\n",
    "Summarise how your Turing machine works,\n",
    "explaining the main transitions and the purpose of each state.\n",
    "Your answer shouldn't be a direct translation of the transition table to English.\n",
    "\n",
    "You may include diagrams, if you wish, drawn by hand or with a computer.\n",
    "See Question 4(a) about how to include diagrams in Markdown.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "MARKS": 8,
    "QUESTION": "5b",
    "TYPE": "ANSWER",
    "cellcol": "answercell",
    "deletable": false
   },
   "source": [
    "*Write your answer to Q5(b) here.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "TYPE": "TEXTBLOCK",
    "deletable": false,
    "editable": false
   },
   "source": [
    "Submit this TMA by zipping together the notebook along\n",
    "with all of the helper and data files you have used, and submitting your .zip\n",
    "file using the online TMA/EMA service.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
